{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark Basic Transformation \n",
    "# MAP vs FLATMAP \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"Basic_Transformation\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#v_list = [10 , 20 ,]\n",
    "range_rdd=spark.sparkContext.range(5,10,1)\n",
    "range_rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[105, 106, 107, 108, 109]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Basic MAP function \n",
    "#Add 100 to all the values in rdd \n",
    "range_rdd_t1 = range_rdd.map(lambda x: x+100)\n",
    "range_rdd_t1.collect()\n",
    "range_rdd_t1.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAP VS FLATMAP  - results are flattened in flatMap output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5, 25, 105), (6, 36, 106), (7, 49, 107), (8, 64, 108), (9, 81, 109)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range_rdd.map(lambda x: (x,x*x , x+100)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatMap ( M is caps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 25, 105, 6, 36, 106, 7, 49, 107, 8, 64, 108, 9, 81, 109]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range_rdd.flatMap(lambda x: (x,x*x , x+100)).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text example Map vs Flatmap . "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Could have read as rdd using spark.sparkcontext for RDD \n",
    "\n",
    "Content of file input_text \n",
    "\n",
    "Big Data learning \n",
    "New to spark .exp in python and sql \n",
    "learning RDD \n",
    "good skills in Python \n",
    "Pandas is what keep my job intresting \n",
    "scaling is still a prob \n",
    "hoping spark can help.  \n",
    "Intro to big data\n",
    "Good database skills sql and no sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df= spark.read.text('input_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df.take(5)\n",
    "type(text_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(value='Big Data learning '),\n",
       " Row(value='New to spark .exp in python and sql '),\n",
       " Row(value='learning RDD '),\n",
       " Row(value='good skills in Python '),\n",
       " Row(value='Pandas is what keep my job intresting '),\n",
       " Row(value='scaling is still a prob '),\n",
       " Row(value='hoping spark can help.  '),\n",
       " Row(value='Intro to big data'),\n",
       " Row(value='Good database skills sql and no sql ')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_rdd = text_df.rdd\n",
    "text_rdd.collect()\n",
    "#type(text_rdd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Big', 'Data', 'learning'],\n",
       " ['New', 'to', 'spark', '.exp', 'in', 'python', 'and', 'sql'],\n",
       " ['learning', 'RDD'],\n",
       " ['good', 'skills', 'in', 'Python'],\n",
       " ['Pandas', 'is', 'what', 'keep', 'my', 'job', 'intresting'],\n",
       " ['scaling', 'is', 'still', 'a', 'prob'],\n",
       " ['hoping', 'spark', 'can', 'help.'],\n",
       " ['Intro', 'to', 'big', 'data'],\n",
       " ['Good', 'database', 'skills', 'sql', 'and', 'no', 'sql']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_rdd.map(lambda x : x.value.split()).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Big',\n",
       " 'Data',\n",
       " 'learning',\n",
       " 'New',\n",
       " 'to',\n",
       " 'spark',\n",
       " '.exp',\n",
       " 'in',\n",
       " 'python',\n",
       " 'and',\n",
       " 'sql',\n",
       " 'learning',\n",
       " 'RDD',\n",
       " 'good',\n",
       " 'skills',\n",
       " 'in',\n",
       " 'Python',\n",
       " 'Pandas',\n",
       " 'is',\n",
       " 'what',\n",
       " 'keep',\n",
       " 'my',\n",
       " 'job',\n",
       " 'intresting',\n",
       " 'scaling',\n",
       " 'is',\n",
       " 'still',\n",
       " 'a',\n",
       " 'prob',\n",
       " 'hoping',\n",
       " 'spark',\n",
       " 'can',\n",
       " 'help.',\n",
       " 'Intro',\n",
       " 'to',\n",
       " 'big',\n",
       " 'data',\n",
       " 'Good',\n",
       " 'database',\n",
       " 'skills',\n",
       " 'sql',\n",
       " 'and',\n",
       " 'no',\n",
       " 'sql']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_rdd.flatMap(lambda x : x.value.split()).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.PipelinedRDD"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#wordcount of file using flatMap\n",
    "\n",
    "rdd1= text_rdd.flatMap(lambda x : x.value.split())\n",
    "type(rdd1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Big', 1),\n",
       " ('Data', 1),\n",
       " ('learning', 1),\n",
       " ('New', 1),\n",
       " ('to', 1),\n",
       " ('spark', 1),\n",
       " ('.exp', 1),\n",
       " ('in', 1),\n",
       " ('python', 1),\n",
       " ('and', 1),\n",
       " ('sql', 1),\n",
       " ('learning', 1),\n",
       " ('RDD', 1),\n",
       " ('good', 1),\n",
       " ('skills', 1),\n",
       " ('in', 1),\n",
       " ('Python', 1),\n",
       " ('Pandas', 1),\n",
       " ('is', 1),\n",
       " ('what', 1),\n",
       " ('keep', 1),\n",
       " ('my', 1),\n",
       " ('job', 1),\n",
       " ('intresting', 1),\n",
       " ('scaling', 1),\n",
       " ('is', 1),\n",
       " ('still', 1),\n",
       " ('a', 1),\n",
       " ('prob', 1),\n",
       " ('hoping', 1),\n",
       " ('spark', 1),\n",
       " ('can', 1),\n",
       " ('help.', 1),\n",
       " ('Intro', 1),\n",
       " ('to', 1),\n",
       " ('big', 1),\n",
       " ('data', 1),\n",
       " ('Good', 1),\n",
       " ('database', 1),\n",
       " ('skills', 1),\n",
       " ('sql', 1),\n",
       " ('and', 1),\n",
       " ('no', 1),\n",
       " ('sql', 1)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd2= rdd1.map(lambda x: (x,1))\n",
    "type(rdd2)\n",
    "rdd2.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Big', 1),\n",
       " ('Data', 1),\n",
       " ('learning', 2),\n",
       " ('New', 1),\n",
       " ('to', 2),\n",
       " ('spark', 2),\n",
       " ('.exp', 1),\n",
       " ('in', 2),\n",
       " ('python', 1),\n",
       " ('and', 2),\n",
       " ('sql', 3),\n",
       " ('RDD', 1),\n",
       " ('good', 1),\n",
       " ('skills', 2),\n",
       " ('Python', 1),\n",
       " ('Pandas', 1),\n",
       " ('is', 2),\n",
       " ('what', 1),\n",
       " ('keep', 1),\n",
       " ('my', 1),\n",
       " ('job', 1),\n",
       " ('intresting', 1),\n",
       " ('scaling', 1),\n",
       " ('still', 1),\n",
       " ('a', 1),\n",
       " ('prob', 1),\n",
       " ('hoping', 1),\n",
       " ('can', 1),\n",
       " ('help.', 1),\n",
       " ('Intro', 1),\n",
       " ('big', 1),\n",
       " ('data', 1),\n",
       " ('Good', 1),\n",
       " ('database', 1),\n",
       " ('no', 1)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# HAVE TO CHECK HOW reducByKey works \n",
    "\n",
    "# Lambda if we have to write as a function :\n",
    "# Define associative function separately \n",
    "#def sumFunc(v1, v2):\n",
    "#    return v1 + V2\n",
    "rdd2.reduceByKey(lambda v1, v2: v1+v2).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
